{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Character-Level Language Model (TinyLLM-like)\n",
        "\n",
        "A simple character-level language model built with PyTorch that learns to predict the next character in a sequence. This project demonstrates the fundamentals of neural language modeling using a lightweight architecture.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This model implements a character-level neural network that can:\n",
        "- Learn patterns from text data\n",
        "- Predict the next character given a context\n",
        "- Generate new text based on learned patterns\n",
        "\n",
        "The architecture is intentionally simple, making it ideal for educational purposes and for understanding the basics of language modeling before moving to more complex architectures.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **Character-level tokenization**: Converts text into character indices\n",
        "- **Embedding-based representation**: Maps characters to dense vector representations\n",
        "- **Simple feed-forward architecture**: Uses embedding → flatten → hidden → output layers\n",
        "- **Training with metrics**: Tracks loss and accuracy during training\n",
        "- **Next-character prediction**: Predicts the most likely next character\n",
        "- **Text generation**: Creates new text from a seed string\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Python 3.6+\n",
        "- PyTorch 1.7+\n",
        "- NumPy\n",
        "- Matplotlib\n",
        "\n",
        "## Quick Start\n",
        "\n",
        "```python\n",
        "# Import the code\n",
        "from tiny_llm import CharacterDataset, TinyLLM, train_model, predict_next_char, generate_text\n",
        "\n",
        "# Define your training text\n",
        "text = \"hello world. this is a tiny language model. it can learn simple patterns from text data.\"\n",
        "\n",
        "# Create dataset and model\n",
        "dataset = CharacterDataset(text, context_size=3)\n",
        "model = TinyLLM(vocab_size=dataset.get_vocab_size(), embedding_dim=16, hidden_dim=32, context_size=3)\n",
        "\n",
        "# Train the model\n",
        "losses, accuracies = train_model(model, dataset, epochs=20, batch_size=8, learning_rate=0.01)\n",
        "\n",
        "# Make predictions\n",
        "next_char, prob = predict_next_char(model, dataset, \"hel\")\n",
        "print(f\"Predicted next character: '{next_char}' with probability {prob:.4f}\")\n",
        "\n",
        "# Generate text\n",
        "generated_text = generate_text(model, dataset, seed_text=\"hel\", length=30)\n",
        "print(f\"Generated text: {generated_text}\")\n",
        "```\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "The model consists of the following components:\n",
        "\n",
        "1. **Embedding Layer**: Converts character indices to dense vectors (dimension: `embedding_dim`)\n",
        "2. **Flattening Operation**: Reshapes the embedded context for the linear layer\n",
        "3. **Hidden Layer**: A linear layer with ReLU activation (dimension: `hidden_dim`)\n",
        "4. **Output Layer**: Produces logits for each character in the vocabulary\n",
        "\n",
        "## Debugging Features\n",
        "\n",
        "The implementation includes several debugging checkpoints:\n",
        "\n",
        "- **Tokenization**: Displays samples from the dataset after tokenization\n",
        "- **Forward Pass**: Prints tensor shapes at each stage of the forward pass\n",
        "- **Training**: Shows loss and accuracy after each epoch\n",
        "- **Prediction**: Displays top predictions with their probabilities\n",
        "\n",
        "## Example Usage\n",
        "\n",
        "### Predicting the Next Character\n",
        "\n",
        "```python\n",
        "# Sample inputs and their predictions\n",
        "sample_inputs = [\"hel\", \"wor\", \"thi\"]\n",
        "\n",
        "for sample in sample_inputs:\n",
        "    next_char, prob = predict_next_char(model, dataset, sample)\n",
        "    print(f\"Input: '{sample}' -> Predicted: '{next_char}' (p={prob:.4f})\")\n",
        "```\n",
        "\n",
        "### Generating Text\n",
        "\n",
        "```python\n",
        "# Generate 30 characters of text starting with \"hel\"\n",
        "generated_text = generate_text(model, dataset, seed_text=\"hel\", length=30)\n",
        "print(f\"Generated text: {generated_text}\")\n",
        "```\n",
        "\n",
        "## Customization\n",
        "\n",
        "You can customize the model by adjusting these hyperparameters:\n",
        "\n",
        "- `context_size`: Number of characters to use as input context\n",
        "- `embedding_dim`: Dimension of character embeddings\n",
        "- `hidden_dim`: Size of hidden layer\n",
        "- `learning_rate`: Controls the speed of training\n",
        "- `batch_size`: Number of samples processed together\n",
        "- `epochs`: Number of complete passes through the training data\n",
        "\n",
        "## Limitations and Future Improvements\n",
        "\n",
        "This model serves as an educational starting point. For better performance, consider:\n",
        "\n",
        "1. Increasing model capacity with more layers or recurrent/transformer architectures\n",
        "2. Moving to word-level or subword-level tokenization\n",
        "3. Using larger and more diverse training data\n",
        "4. Implementing temperature scaling for more diverse text generation\n",
        "5. Adding attention mechanisms for handling longer contexts\n",
        "\n",
        "## Google Colab Support\n",
        "\n",
        "This model is designed to run in Google Colab without any special requirements. Simply copy the code into a Colab notebook and execute it.\n",
        "\n",
        "## License\n",
        "\n",
        "MIT License - Feel free to use, modify, and distribute this code for educational purposes."
      ],
      "metadata": {
        "id": "73itU5CDZ3VN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_6RhrAb7ZexG",
        "outputId": "b18501f0-1506-452f-855c-45d046f5a2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'hello world. this is a tiny language model. it can learn simple patterns from text data. let's see how well it works!'\n",
            "Vocabulary: [' ', '!', \"'\", '.', 'a', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'x', 'y']\n",
            "Vocabulary size: 25\n",
            "\n",
            "----- TOKENIZATION CHECKPOINT -----\n",
            "Sample 1: Input 'hel' -> Target 'l'\n",
            "Sample 2: Input 'ell' -> Target 'o'\n",
            "Sample 3: Input 'llo' -> Target ' '\n",
            "\n",
            "----- MODEL ARCHITECTURE -----\n",
            "TinyLLM(\n",
            "  (embedding): Embedding(25, 16)\n",
            "  (hidden): Linear(in_features=48, out_features=32, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (output): Linear(in_features=32, out_features=25, bias=True)\n",
            ")\n",
            "\n",
            "----- FORWARD PASS CHECKPOINT -----\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Input shape: torch.Size([1, 3])\n",
            "Output shape: torch.Size([1, 25])\n",
            "\n",
            "----- TRAINING CHECKPOINT -----\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 1/20, Loss: 3.1170, Accuracy: 0.0877\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 2/20, Loss: 2.4973, Accuracy: 0.2895\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 3/20, Loss: 1.9294, Accuracy: 0.4298\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 4/20, Loss: 1.4703, Accuracy: 0.5351\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 5/20, Loss: 1.0908, Accuracy: 0.6316\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 6/20, Loss: 0.7920, Accuracy: 0.7368\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 7/20, Loss: 0.5586, Accuracy: 0.8684\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 8/20, Loss: 0.4691, Accuracy: 0.9035\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 9/20, Loss: 0.3751, Accuracy: 0.8947\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 10/20, Loss: 0.3110, Accuracy: 0.9211\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 11/20, Loss: 0.2326, Accuracy: 0.9386\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 12/20, Loss: 0.1689, Accuracy: 0.9211\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 13/20, Loss: 0.1546, Accuracy: 0.9298\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 14/20, Loss: 0.1496, Accuracy: 0.9298\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 15/20, Loss: 0.1739, Accuracy: 0.9474\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 16/20, Loss: 0.1294, Accuracy: 0.9298\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 17/20, Loss: 0.1228, Accuracy: 0.9386\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 18/20, Loss: 0.1143, Accuracy: 0.9386\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 19/20, Loss: 0.0912, Accuracy: 0.9474\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([8, 3, 16])\n",
            "Shape after flattening: torch.Size([8, 48])\n",
            "Shape after hidden layer: torch.Size([8, 32])\n",
            "Shape of output logits: torch.Size([8, 25])\n",
            "Shape after embedding: torch.Size([2, 3, 16])\n",
            "Shape after flattening: torch.Size([2, 48])\n",
            "Shape after hidden layer: torch.Size([2, 32])\n",
            "Shape of output logits: torch.Size([2, 25])\n",
            "Epoch 20/20, Loss: 0.1022, Accuracy: 0.9298\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- SAMPLE INPUTS/OUTPUTS -----\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "\n",
            "Predictions for context 'hel':\n",
            "  1. 'l' with probability 0.9941\n",
            "  2. ' ' with probability 0.0048\n",
            "  3. 'k' with probability 0.0005\n",
            "Input: 'hel' -> Predicted next character: 'l' (probability: 0.9941)\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "\n",
            "Predictions for context 'wor':\n",
            "  1. 'l' with probability 0.5074\n",
            "  2. 'k' with probability 0.4824\n",
            "  3. 'n' with probability 0.0040\n",
            "Input: 'wor' -> Predicted next character: 'l' (probability: 0.5074)\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "\n",
            "Predictions for context 'thi':\n",
            "  1. 's' with probability 0.9976\n",
            "  2. 't' with probability 0.0010\n",
            "  3. ' ' with probability 0.0006\n",
            "Input: 'thi' -> Predicted next character: 's' (probability: 0.9976)\n",
            "\n",
            "----- CUSTOM TEST STRING -----\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "\n",
            "Predictions for context 'he ':\n",
            "  1. 'h' with probability 0.6920\n",
            "  2. 'm' with probability 0.1218\n",
            "  3. 't' with probability 0.1218\n",
            "Input: 'the ' -> Predicted next character: 'h' (probability: 0.6920)\n",
            "\n",
            "----- TEXT GENERATION -----\n",
            "\n",
            "Generating text from seed: 'hel'\n",
            "Context: 'hel'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'l', Updated context: 'ell'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: 'll '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'i', Updated context: 'l i'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 't', Updated context: ' it'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: 'it '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'w', Updated context: 't w'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'o', Updated context: ' wo'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'r', Updated context: 'wor'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'k', Updated context: 'ork'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 's', Updated context: 'rks'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: '!', Updated context: 'ks!'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'e', Updated context: 's!e'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: '!e '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'l', Updated context: 'e l'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'o', Updated context: ' lo'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 't', Updated context: 'lot'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ''', Updated context: 'ot''\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'r', Updated context: 't'r'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: ''r '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 's', Updated context: 'r s'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'e', Updated context: ' se'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'e', Updated context: 'see'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: 'ee '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'h', Updated context: 'e h'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'o', Updated context: ' ho'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'w', Updated context: 'how'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: ' ', Updated context: 'ow '\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'w', Updated context: 'w w'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'e', Updated context: ' we'\n",
            "Shape after embedding: torch.Size([1, 3, 16])\n",
            "Shape after flattening: torch.Size([1, 48])\n",
            "Shape after hidden layer: torch.Size([1, 32])\n",
            "Shape of output logits: torch.Size([1, 25])\n",
            "Next char: 'l', Updated context: 'wel'\n",
            "\n",
            "Generated text (seed: 'hel'): 'hell it works!e lot'r see how wel'\n",
            "\n",
            "----- FUTURE IMPROVEMENTS -----\n",
            "1. Increase model capacity with more layers or recurrent/transformer architecture\n",
            "2. Move to word-level or subword-level tokenization for better semantic understanding\n",
            "3. Use larger dataset for training\n",
            "4. Implement temperature scaling for more diverse text generation\n",
            "5. Add attention mechanisms for handling longer contexts\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# ----- DATA PREPARATION -----\n",
        "\n",
        "# Custom dataset for character-level language modeling\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, text, context_size=3):\n",
        "        \"\"\"\n",
        "        Initialize the character-level dataset.\n",
        "\n",
        "        Args:\n",
        "            text (str): The training text\n",
        "            context_size (int): Number of characters to use as context\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "        self.context_size = context_size\n",
        "\n",
        "        # Create character to index mapping\n",
        "        self.chars = sorted(list(set(text)))\n",
        "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
        "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "        # Create training samples\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "\n",
        "        for i in range(len(text) - context_size):\n",
        "            context = text[i:i+context_size]\n",
        "            target = text[i+context_size]\n",
        "\n",
        "            # Convert characters to indices\n",
        "            context_idx = [self.char_to_idx[c] for c in context]\n",
        "            target_idx = self.char_to_idx[target]\n",
        "\n",
        "            self.X.append(context_idx)\n",
        "            self.y.append(target_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def decode(self, indices):\n",
        "        \"\"\"Convert a list of indices back to characters\"\"\"\n",
        "        return ''.join([self.idx_to_char[idx.item()] for idx in indices])\n",
        "\n",
        "# ----- MODEL DEFINITION -----\n",
        "\n",
        "class TinyLLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=16, hidden_dim=32, context_size=3):\n",
        "        \"\"\"\n",
        "        Initialize the TinyLLM model.\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the vocabulary\n",
        "            embedding_dim (int): Dimension of character embeddings\n",
        "            hidden_dim (int): Dimension of hidden layer\n",
        "            context_size (int): Number of characters in the input context\n",
        "        \"\"\"\n",
        "        super(TinyLLM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.context_size = context_size\n",
        "\n",
        "        # Embedding layer: maps character indices to dense vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # After embedding, the shape will be [batch_size, context_size, embedding_dim]\n",
        "        # We'll flatten this to [batch_size, context_size * embedding_dim]\n",
        "\n",
        "        # Linear hidden layer with ReLU activation\n",
        "        self.hidden = nn.Linear(context_size * embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output layer: produces logits for each possible next character\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape [batch_size, context_size]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape [batch_size, vocab_size]\n",
        "        \"\"\"\n",
        "        # [batch_size, context_size] -> [batch_size, context_size, embedding_dim]\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Checkpoint: Print shape after embedding\n",
        "        print(f\"Shape after embedding: {embedded.shape}\")\n",
        "\n",
        "        # Flatten the embedded context\n",
        "        # [batch_size, context_size, embedding_dim] -> [batch_size, context_size * embedding_dim]\n",
        "        flattened = embedded.view(embedded.size(0), -1)\n",
        "\n",
        "        # Checkpoint: Print shape after flattening\n",
        "        print(f\"Shape after flattening: {flattened.shape}\")\n",
        "\n",
        "        # Pass through hidden layer with ReLU activation\n",
        "        hidden = self.relu(self.hidden(flattened))\n",
        "\n",
        "        # Checkpoint: Print shape after hidden layer\n",
        "        print(f\"Shape after hidden layer: {hidden.shape}\")\n",
        "\n",
        "        # Output layer produces logits for next character prediction\n",
        "        logits = self.output(hidden)\n",
        "\n",
        "        # Checkpoint: Print shape of output logits\n",
        "        print(f\"Shape of output logits: {logits.shape}\")\n",
        "\n",
        "        return logits\n",
        "\n",
        "# ----- TRAINING FUNCTION -----\n",
        "\n",
        "def train_model(model, dataset, epochs=10, batch_size=32, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Train the TinyLLM model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train\n",
        "        dataset (Dataset): The dataset to train on\n",
        "        epochs (int): Number of training epochs\n",
        "        batch_size (int): Batch size for training\n",
        "        learning_rate (float): Learning rate for optimizer\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of losses and accuracies per epoch\n",
        "    \"\"\"\n",
        "    # Create DataLoader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Lists to store metrics\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        # Disable print statements after first epoch to reduce output\n",
        "        verbose = (epoch == 0)\n",
        "\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            # Forward pass\n",
        "            logits = model(X_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct_predictions += (predicted == y_batch).sum().item()\n",
        "            total_predictions += y_batch.size(0)\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = total_loss / len(dataloader)\n",
        "        epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "        # Store metrics\n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_accuracy)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "    return losses, accuracies\n",
        "\n",
        "# ----- PREDICTION FUNCTION -----\n",
        "\n",
        "def predict_next_char(model, dataset, context, topk=3):\n",
        "    \"\"\"\n",
        "    Predict the next character given a context.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model\n",
        "        dataset (CharacterDataset): Dataset containing character mappings\n",
        "        context (str): Context string to predict from\n",
        "        topk (int): Number of top predictions to return\n",
        "\n",
        "    Returns:\n",
        "        tuple: Most likely next character and probability\n",
        "    \"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    # Make sure context is the right length for the model\n",
        "    if len(context) > model.context_size:\n",
        "        context = context[-model.context_size:]\n",
        "    elif len(context) < model.context_size:\n",
        "        # Pad with spaces if context is too short (less likely scenario)\n",
        "        context = ' ' * (model.context_size - len(context)) + context\n",
        "\n",
        "    # Convert context to indices\n",
        "    context_idx = [dataset.char_to_idx.get(c, 0) for c in context]  # Use 0 as default if char not found\n",
        "    x = torch.tensor([context_idx], dtype=torch.long)\n",
        "\n",
        "    # Get model prediction\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Get top k predictions\n",
        "    topk_probs, topk_indices = torch.topk(probabilities, topk, dim=1)\n",
        "\n",
        "    # Print top predictions and their probabilities\n",
        "    print(f\"\\nPredictions for context '{context}':\")\n",
        "    for i in range(topk):\n",
        "        char_idx = topk_indices[0][i].item()\n",
        "        prob = topk_probs[0][i].item()\n",
        "        char = dataset.idx_to_char[char_idx]\n",
        "        print(f\"  {i+1}. '{char}' with probability {prob:.4f}\")\n",
        "\n",
        "    # Return most likely character and its probability\n",
        "    best_idx = topk_indices[0][0].item()\n",
        "    best_char = dataset.idx_to_char[best_idx]\n",
        "    best_prob = topk_probs[0][0].item()\n",
        "\n",
        "    return best_char, best_prob\n",
        "\n",
        "# ----- TEXT GENERATION FUNCTION -----\n",
        "\n",
        "def generate_text(model, dataset, seed_text, length=20):\n",
        "    \"\"\"\n",
        "    Generate text from the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model\n",
        "        dataset (CharacterDataset): Dataset containing character mappings\n",
        "        seed_text (str): Starting text for generation\n",
        "        length (int): Number of characters to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    context_size = model.context_size\n",
        "\n",
        "    # Make sure seed text is the right length for the model\n",
        "    if len(seed_text) > context_size:\n",
        "        context = seed_text[-context_size:]\n",
        "    else:\n",
        "        # Pad with spaces if seed is too short\n",
        "        context = ' ' * (context_size - len(seed_text)) + seed_text\n",
        "\n",
        "    result = seed_text\n",
        "\n",
        "    print(f\"\\nGenerating text from seed: '{seed_text}'\")\n",
        "    print(f\"Context: '{context}'\")\n",
        "\n",
        "    # Generate characters one by one\n",
        "    for _ in range(length):\n",
        "        # Convert context to indices\n",
        "        context_idx = [dataset.char_to_idx.get(c, 0) for c in context]  # Use 0 as default if char not found\n",
        "        x = torch.tensor([context_idx], dtype=torch.long)\n",
        "\n",
        "        # Get model prediction\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
        "        next_char = dataset.idx_to_char[next_char_idx]\n",
        "\n",
        "        # Update context and result\n",
        "        context = context[1:] + next_char\n",
        "        result += next_char\n",
        "\n",
        "        print(f\"Next char: '{next_char}', Updated context: '{context}'\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# ----- MAIN EXECUTION -----\n",
        "\n",
        "def main():\n",
        "    # Define training text\n",
        "    text = \"hello world. this is a tiny language model. it can learn simple patterns from text data. let's see how well it works!\"\n",
        "\n",
        "    # Create dataset\n",
        "    context_size = 3\n",
        "    dataset = CharacterDataset(text, context_size=context_size)\n",
        "\n",
        "    # Print dataset information\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Vocabulary: {dataset.chars}\")\n",
        "    print(f\"Vocabulary size: {dataset.vocab_size}\")\n",
        "\n",
        "    # Checkpoint: Show sample from dataset\n",
        "    print(\"\\n----- TOKENIZATION CHECKPOINT -----\")\n",
        "    for i in range(3):\n",
        "        X, y = dataset[i]\n",
        "        context_chars = dataset.decode(X)\n",
        "        target_char = dataset.idx_to_char[y.item()]\n",
        "        print(f\"Sample {i+1}: Input '{context_chars}' -> Target '{target_char}'\")\n",
        "\n",
        "    # Create model\n",
        "    vocab_size = dataset.get_vocab_size()\n",
        "    model = TinyLLM(vocab_size, embedding_dim=16, hidden_dim=32, context_size=context_size)\n",
        "\n",
        "    # Print model information\n",
        "    print(\"\\n----- MODEL ARCHITECTURE -----\")\n",
        "    print(model)\n",
        "\n",
        "    # Test a forward pass\n",
        "    print(\"\\n----- FORWARD PASS CHECKPOINT -----\")\n",
        "    X_sample, y_sample = dataset[0]\n",
        "    X_sample = X_sample.unsqueeze(0)  # Add batch dimension\n",
        "    output = model(X_sample)\n",
        "    print(f\"Input shape: {X_sample.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\n----- TRAINING CHECKPOINT -----\")\n",
        "    losses, accuracies = train_model(model, dataset, epochs=20, batch_size=8, learning_rate=0.01)\n",
        "\n",
        "    # Plot training metrics\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accuracies)\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Test the model with sample inputs\n",
        "    print(\"\\n----- SAMPLE INPUTS/OUTPUTS -----\")\n",
        "    sample_inputs = [\"hel\", \"wor\", \"thi\"]\n",
        "\n",
        "    for sample in sample_inputs:\n",
        "        next_char, prob = predict_next_char(model, dataset, sample)\n",
        "        print(f\"Input: '{sample}' -> Predicted next character: '{next_char}' (probability: {prob:.4f})\")\n",
        "\n",
        "    # Test with custom string\n",
        "    custom_test = \"the \"\n",
        "    print(\"\\n----- CUSTOM TEST STRING -----\")\n",
        "    next_char, prob = predict_next_char(model, dataset, custom_test)\n",
        "    print(f\"Input: '{custom_test}' -> Predicted next character: '{next_char}' (probability: {prob:.4f})\")\n",
        "\n",
        "    # Generate text\n",
        "    print(\"\\n----- TEXT GENERATION -----\")\n",
        "    seed = \"hel\"\n",
        "    generated_text = generate_text(model, dataset, seed, length=30)\n",
        "    print(f\"\\nGenerated text (seed: '{seed}'): '{generated_text}'\")\n",
        "\n",
        "    # Final thoughts\n",
        "    print(\"\\n----- FUTURE IMPROVEMENTS -----\")\n",
        "    print(\"1. Increase model capacity with more layers or recurrent/transformer architecture\")\n",
        "    print(\"2. Move to word-level or subword-level tokenization for better semantic understanding\")\n",
        "    print(\"3. Use larger dataset for training\")\n",
        "    print(\"4. Implement temperature scaling for more diverse text generation\")\n",
        "    print(\"5. Add attention mechanisms for handling longer contexts\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# ----- DATA PREPARATION -----\n",
        "\n",
        "# Custom dataset for character-level language modeling\n",
        "class CharacterDataset(Dataset):\n",
        "    def __init__(self, text, context_size=3):\n",
        "        \"\"\"\n",
        "        Initialize the character-level dataset.\n",
        "\n",
        "        Args:\n",
        "            text (str): The training text\n",
        "            context_size (int): Number of characters to use as context\n",
        "        \"\"\"\n",
        "        self.text = text\n",
        "        self.context_size = context_size\n",
        "\n",
        "        # Create character to index mapping\n",
        "        self.chars = sorted(list(set(text)))\n",
        "        self.char_to_idx = {ch: i for i, ch in enumerate(self.chars)}\n",
        "        self.idx_to_char = {i: ch for i, ch in enumerate(self.chars)}\n",
        "        self.vocab_size = len(self.chars)\n",
        "\n",
        "        # Create training samples\n",
        "        self.X = []\n",
        "        self.y = []\n",
        "\n",
        "        for i in range(len(text) - context_size):\n",
        "            context = text[i:i+context_size]\n",
        "            target = text[i+context_size]\n",
        "\n",
        "            # Convert characters to indices\n",
        "            context_idx = [self.char_to_idx[c] for c in context]\n",
        "            target_idx = self.char_to_idx[target]\n",
        "\n",
        "            self.X.append(context_idx)\n",
        "            self.y.append(target_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def decode(self, indices):\n",
        "        \"\"\"Convert a list of indices back to characters\"\"\"\n",
        "        return ''.join([self.idx_to_char[idx.item()] for idx in indices])\n",
        "\n",
        "# ----- MODEL DEFINITION -----\n",
        "\n",
        "class TinyLLM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=16, hidden_dim=32, context_size=3):\n",
        "        \"\"\"\n",
        "        Initialize the TinyLLM model.\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the vocabulary\n",
        "            embedding_dim (int): Dimension of character embeddings\n",
        "            hidden_dim (int): Dimension of hidden layer\n",
        "            context_size (int): Number of characters in the input context\n",
        "        \"\"\"\n",
        "        super(TinyLLM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.context_size = context_size\n",
        "\n",
        "        # Embedding layer: maps character indices to dense vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # After embedding, the shape will be [batch_size, context_size, embedding_dim]\n",
        "        # We'll flatten this to [batch_size, context_size * embedding_dim]\n",
        "\n",
        "        # Linear hidden layer with ReLU activation\n",
        "        self.hidden = nn.Linear(context_size * embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Output layer: produces logits for each possible next character\n",
        "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape [batch_size, context_size]\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape [batch_size, vocab_size]\n",
        "        \"\"\"\n",
        "        # [batch_size, context_size] -> [batch_size, context_size, embedding_dim]\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Checkpoint: Print shape after embedding\n",
        "        print(f\"Shape after embedding: {embedded.shape}\")\n",
        "\n",
        "        # Flatten the embedded context\n",
        "        # [batch_size, context_size, embedding_dim] -> [batch_size, context_size * embedding_dim]\n",
        "        flattened = embedded.view(embedded.size(0), -1)\n",
        "\n",
        "        # Checkpoint: Print shape after flattening\n",
        "        print(f\"Shape after flattening: {flattened.shape}\")\n",
        "\n",
        "        # Pass through hidden layer with ReLU activation\n",
        "        hidden = self.relu(self.hidden(flattened))\n",
        "\n",
        "        # Checkpoint: Print shape after hidden layer\n",
        "        print(f\"Shape after hidden layer: {hidden.shape}\")\n",
        "\n",
        "        # Output layer produces logits for next character prediction\n",
        "        logits = self.output(hidden)\n",
        "\n",
        "        # Checkpoint: Print shape of output logits\n",
        "        print(f\"Shape of output logits: {logits.shape}\")\n",
        "\n",
        "        return logits\n",
        "\n",
        "# ----- TRAINING FUNCTION -----\n",
        "\n",
        "def train_model(model, dataset, epochs=10, batch_size=32, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Train the TinyLLM model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train\n",
        "        dataset (Dataset): The dataset to train on\n",
        "        epochs (int): Number of training epochs\n",
        "        batch_size (int): Batch size for training\n",
        "        learning_rate (float): Learning rate for optimizer\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of losses and accuracies per epoch\n",
        "    \"\"\"\n",
        "    # Create DataLoader\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Lists to store metrics\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        # Disable print statements after first epoch to reduce output\n",
        "        verbose = (epoch == 0)\n",
        "\n",
        "        for X_batch, y_batch in dataloader:\n",
        "            # Forward pass\n",
        "            logits = model(X_batch)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct_predictions += (predicted == y_batch).sum().item()\n",
        "            total_predictions += y_batch.size(0)\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = total_loss / len(dataloader)\n",
        "        epoch_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "        # Store metrics\n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_accuracy)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "\n",
        "    return losses, accuracies\n",
        "\n",
        "# ----- PREDICTION FUNCTION -----\n",
        "\n",
        "def predict_next_char(model, dataset, context, topk=3):\n",
        "    \"\"\"\n",
        "    Predict the next character given a context.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model\n",
        "        dataset (CharacterDataset): Dataset containing character mappings\n",
        "        context (str): Context string to predict from\n",
        "        topk (int): Number of top predictions to return\n",
        "\n",
        "    Returns:\n",
        "        tuple: Most likely next character and probability\n",
        "    \"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "\n",
        "    # Make sure context is the right length for the model\n",
        "    if len(context) > model.context_size:\n",
        "        context = context[-model.context_size:]\n",
        "    elif len(context) < model.context_size:\n",
        "        # Pad with spaces if context is too short (less likely scenario)\n",
        "        context = ' ' * (model.context_size - len(context)) + context\n",
        "\n",
        "    # Convert context to indices\n",
        "    context_idx = [dataset.char_to_idx.get(c, 0) for c in context]  # Use 0 as default if char not found\n",
        "    x = torch.tensor([context_idx], dtype=torch.long)\n",
        "\n",
        "    # Get model prediction\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "    # Get top k predictions\n",
        "    topk_probs, topk_indices = torch.topk(probabilities, topk, dim=1)\n",
        "\n",
        "    # Print top predictions and their probabilities\n",
        "    print(f\"\\nPredictions for context '{context}':\")\n",
        "    for i in range(topk):\n",
        "        char_idx = topk_indices[0][i].item()\n",
        "        prob = topk_probs[0][i].item()\n",
        "        char = dataset.idx_to_char[char_idx]\n",
        "        print(f\"  {i+1}. '{char}' with probability {prob:.4f}\")\n",
        "\n",
        "    # Return most likely character and its probability\n",
        "    best_idx = topk_indices[0][0].item()\n",
        "    best_char = dataset.idx_to_char[best_idx]\n",
        "    best_prob = topk_probs[0][0].item()\n",
        "\n",
        "    return best_char, best_prob\n",
        "\n",
        "# ----- TEXT GENERATION FUNCTION -----\n",
        "\n",
        "def generate_text(model, dataset, seed_text, length=20):\n",
        "    \"\"\"\n",
        "    Generate text from the model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained model\n",
        "        dataset (CharacterDataset): Dataset containing character mappings\n",
        "        seed_text (str): Starting text for generation\n",
        "        length (int): Number of characters to generate\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    context_size = model.context_size\n",
        "\n",
        "    # Make sure seed text is the right length for the model\n",
        "    if len(seed_text) > context_size:\n",
        "        context = seed_text[-context_size:]\n",
        "    else:\n",
        "        # Pad with spaces if seed is too short\n",
        "        context = ' ' * (context_size - len(seed_text)) + seed_text\n",
        "\n",
        "    result = seed_text\n",
        "\n",
        "    print(f\"\\nGenerating text from seed: '{seed_text}'\")\n",
        "    print(f\"Context: '{context}'\")\n",
        "\n",
        "    # Generate characters one by one\n",
        "    for _ in range(length):\n",
        "        # Convert context to indices\n",
        "        context_idx = [dataset.char_to_idx.get(c, 0) for c in context]  # Use 0 as default if char not found\n",
        "        x = torch.tensor([context_idx], dtype=torch.long)\n",
        "\n",
        "        # Get model prediction\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "\n",
        "        # Convert logits to probabilities\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
        "        next_char = dataset.idx_to_char[next_char_idx]\n",
        "\n",
        "        # Update context and result\n",
        "        context = context[1:] + next_char\n",
        "        result += next_char\n",
        "\n",
        "        print(f\"Next char: '{next_char}', Updated context: '{context}'\")\n",
        "\n",
        "    return result\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def setup_logging_and_outputs(base_dir='tiny_llm_outputs'):\n",
        "    \"\"\"\n",
        "    Set up logging and output directories for saving results.\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): Base directory for all outputs\n",
        "\n",
        "    Returns:\n",
        "        tuple: (log_file_path, model_save_path, results_path)\n",
        "    \"\"\"\n",
        "    # Create timestamp for unique folder\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = f\"{base_dir}_{timestamp}\"\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/models\", exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/results\", exist_ok=True)\n",
        "\n",
        "    # Set up logging\n",
        "    log_file_path = f\"{output_dir}/training_log.txt\"\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(log_file_path),\n",
        "            logging.StreamHandler()  # Also output to console\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Paths for model and results\n",
        "    model_save_path = f\"{output_dir}/models/tiny_llm_model.pth\"\n",
        "    results_path = f\"{output_dir}/results\"\n",
        "\n",
        "    logging.info(f\"Output directory created at: {output_dir}\")\n",
        "\n",
        "    return log_file_path, model_save_path, results_path\n",
        "\n",
        "def save_model_and_metrics(model, losses, accuracies, model_save_path, results_path):\n",
        "    \"\"\"\n",
        "    Save model weights and training metrics.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model\n",
        "        losses (list): List of training losses\n",
        "        accuracies (list): List of training accuracies\n",
        "        model_save_path (str): Path to save model weights\n",
        "        results_path (str): Path to save metrics\n",
        "    \"\"\"\n",
        "    # Save model weights\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    logging.info(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "    # Save metrics\n",
        "    metrics = {\n",
        "        'losses': losses,\n",
        "        'accuracies': accuracies\n",
        "    }\n",
        "    with open(f\"{results_path}/training_metrics.json\", 'w') as f:\n",
        "        json.dump(metrics, f)\n",
        "    logging.info(f\"Training metrics saved to {results_path}/training_metrics.json\")\n",
        "\n",
        "    # Save metrics plot\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accuracies)\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{results_path}/training_metrics.png\")\n",
        "    logging.info(f\"Training metrics plot saved to {results_path}/training_metrics.png\")\n",
        "\n",
        "def save_predictions(sample_inputs, predictions, results_path):\n",
        "    \"\"\"\n",
        "    Save model predictions.\n",
        "\n",
        "    Args:\n",
        "        sample_inputs (list): List of input strings\n",
        "        predictions (list): List of (predicted_char, probability) tuples\n",
        "        results_path (str): Path to save predictions\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for i, (input_text, (pred_char, prob)) in enumerate(zip(sample_inputs, predictions)):\n",
        "        results[input_text] = {\n",
        "            'predicted_character': pred_char,\n",
        "            'probability': prob\n",
        "        }\n",
        "\n",
        "    with open(f\"{results_path}/predictions.json\", 'w') as f:\n",
        "        json.dump(results, f)\n",
        "    logging.info(f\"Predictions saved to {results_path}/predictions.json\")\n",
        "\n",
        "def save_generated_text(seed_text, generated_text, results_path):\n",
        "    \"\"\"\n",
        "    Save generated text.\n",
        "\n",
        "    Args:\n",
        "        seed_text (str): Seed text used for generation\n",
        "        generated_text (str): Generated text\n",
        "        results_path (str): Path to save generated text\n",
        "    \"\"\"\n",
        "    with open(f\"{results_path}/generated_text.txt\", 'w') as f:\n",
        "        f.write(f\"Seed: {seed_text}\\n\\n\")\n",
        "        f.write(f\"Generated text: {generated_text}\")\n",
        "    logging.info(f\"Generated text saved to {results_path}/generated_text.txt\")\n",
        "\n",
        "def capture_output(func, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Capture stdout output from a function.\n",
        "\n",
        "    Args:\n",
        "        func: Function to call\n",
        "        *args, **kwargs: Arguments to pass to the function\n",
        "\n",
        "    Returns:\n",
        "        tuple: (function return value, captured output)\n",
        "    \"\"\"\n",
        "    f = io.StringIO()\n",
        "    with redirect_stdout(f):\n",
        "        result = func(*args, **kwargs)\n",
        "    output = f.getvalue()\n",
        "    return result, output\n",
        "\n",
        "def save_dataset_info(dataset, results_path):\n",
        "    \"\"\"\n",
        "    Save dataset information.\n",
        "\n",
        "    Args:\n",
        "        dataset (CharacterDataset): Dataset object\n",
        "        results_path (str): Path to save dataset info\n",
        "    \"\"\"\n",
        "    dataset_info = {\n",
        "        'vocab_size': dataset.vocab_size,\n",
        "        'context_size': dataset.context_size,\n",
        "        'vocabulary': dataset.chars,\n",
        "        'char_to_idx': dataset.char_to_idx,\n",
        "        'num_samples': len(dataset)\n",
        "    }\n",
        "\n",
        "    with open(f\"{results_path}/dataset_info.json\", 'w') as f:\n",
        "        json.dump(dataset_info, f)\n",
        "    logging.info(f\"Dataset info saved to {results_path}/dataset_info.json\")\n",
        "\n",
        "# ----- MAIN EXECUTION -----\n",
        "def main():\n",
        "    # Set up logging and output directories\n",
        "    log_file, model_save_path, results_path = setup_logging_and_outputs()\n",
        "    logging.info(\"Starting TinyLLM training and evaluation\")\n",
        "\n",
        "    # Define training text\n",
        "    text = \"hello world. this is a tiny language model. it can learn simple patterns from text data. let's see how well it works!\"\n",
        "    logging.info(f\"Training text: '{text}'\")\n",
        "\n",
        "    # Create dataset\n",
        "    context_size = 3\n",
        "    dataset = CharacterDataset(text, context_size=context_size)\n",
        "    save_dataset_info(dataset, results_path)\n",
        "\n",
        "    # Print dataset information\n",
        "    logging.info(f\"Vocabulary size: {dataset.vocab_size}\")\n",
        "\n",
        "    # Checkpoint: Show sample from dataset\n",
        "    logging.info(\"\\n----- TOKENIZATION CHECKPOINT -----\")\n",
        "    for i in range(3):\n",
        "        X, y = dataset[i]\n",
        "        context_chars = dataset.decode(X)\n",
        "        target_char = dataset.idx_to_char[y.item()]\n",
        "        logging.info(f\"Sample {i+1}: Input '{context_chars}' -> Target '{target_char}'\")\n",
        "\n",
        "    # Create model\n",
        "    vocab_size = dataset.get_vocab_size()\n",
        "    model = TinyLLM(vocab_size, embedding_dim=16, hidden_dim=32, context_size=context_size)\n",
        "\n",
        "    # Print model information\n",
        "    logging.info(\"\\n----- MODEL ARCHITECTURE -----\")\n",
        "    model_architecture = str(model)\n",
        "    logging.info(model_architecture)\n",
        "    with open(f\"{results_path}/model_architecture.txt\", 'w') as f:\n",
        "        f.write(model_architecture)\n",
        "\n",
        "    # Test a forward pass\n",
        "    logging.info(\"\\n----- FORWARD PASS CHECKPOINT -----\")\n",
        "    X_sample, y_sample = dataset[0]\n",
        "    X_sample = X_sample.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Capture output of forward pass\n",
        "    def forward_pass():\n",
        "        output = model(X_sample)\n",
        "        print(f\"Input shape: {X_sample.shape}\")\n",
        "        print(f\"Output shape: {output.shape}\")\n",
        "        return output\n",
        "\n",
        "    output, forward_output = capture_output(forward_pass)\n",
        "    logging.info(forward_output)\n",
        "\n",
        "    # Train the model\n",
        "    logging.info(\"\\n----- TRAINING CHECKPOINT -----\")\n",
        "\n",
        "    # Capture output of training\n",
        "    def training():\n",
        "        return train_model(model, dataset, epochs=20, batch_size=8, learning_rate=0.01)\n",
        "\n",
        "    (losses, accuracies), training_output = capture_output(training)\n",
        "    logging.info(training_output)\n",
        "\n",
        "    # Save model and metrics\n",
        "    save_model_and_metrics(model, losses, accuracies, model_save_path, results_path)\n",
        "\n",
        "    # Test the model with sample inputs\n",
        "    logging.info(\"\\n----- SAMPLE INPUTS/OUTPUTS -----\")\n",
        "    sample_inputs = [\"hel\", \"wor\", \"thi\"]\n",
        "    predictions = []\n",
        "\n",
        "    for sample in sample_inputs:\n",
        "        # Capture output of prediction\n",
        "        def predict():\n",
        "            return predict_next_char(model, dataset, sample)\n",
        "\n",
        "        (next_char, prob), prediction_output = capture_output(predict)\n",
        "        logging.info(prediction_output)\n",
        "        logging.info(f\"Input: '{sample}' -> Predicted next character: '{next_char}' (probability: {prob:.4f})\")\n",
        "        predictions.append((next_char, prob))\n",
        "\n",
        "    save_predictions(sample_inputs, predictions, results_path)\n",
        "\n",
        "    # Test with custom string\n",
        "    custom_test = \"the \"\n",
        "    logging.info(\"\\n----- CUSTOM TEST STRING -----\")\n",
        "\n",
        "    # Capture output of custom test\n",
        "    def custom_predict():\n",
        "        return predict_next_char(model, dataset, custom_test)\n",
        "\n",
        "    (next_char, prob), custom_output = capture_output(custom_predict)\n",
        "    logging.info(custom_output)\n",
        "    logging.info(f\"Input: '{custom_test}' -> Predicted next character: '{next_char}' (probability: {prob:.4f})\")\n",
        "\n",
        "    # Generate text\n",
        "    logging.info(\"\\n----- TEXT GENERATION -----\")\n",
        "    seed = \"hel\"\n",
        "\n",
        "    # Capture output of text generation\n",
        "    def generate():\n",
        "        return generate_text(model, dataset, seed, length=30)\n",
        "\n",
        "    generated_text, generation_output = capture_output(generate)\n",
        "    logging.info(generation_output)\n",
        "    logging.info(f\"\\nGenerated text (seed: '{seed}'): '{generated_text}'\")\n",
        "\n",
        "    save_generated_text(seed, generated_text, results_path)\n",
        "\n",
        "    # Final thoughts\n",
        "    logging.info(\"\\n----- FUTURE IMPROVEMENTS -----\")\n",
        "    improvements = [\n",
        "        \"1. Increase model capacity with more layers or recurrent/transformer architecture\",\n",
        "        \"2. Move to word-level or subword-level tokenization for better semantic understanding\",\n",
        "        \"3. Use larger dataset for training\",\n",
        "        \"4. Implement temperature scaling for more diverse text generation\",\n",
        "        \"5. Add attention mechanisms for handling longer contexts\"\n",
        "    ]\n",
        "\n",
        "    for improvement in improvements:\n",
        "        logging.info(improvement)\n",
        "\n",
        "    with open(f\"{results_path}/improvement_suggestions.txt\", 'w') as f:\n",
        "        f.write(\"\\n\".join(improvements))\n",
        "\n",
        "    logging.info(f\"\\nAll results saved to directory: {os.path.dirname(log_file)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "sugb810veG0X",
        "outputId": "c6dcf39c-1d5c-4b02-eb4f-0a755f434206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}